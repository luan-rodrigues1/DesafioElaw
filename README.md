# Desafio Elaw - Sistema de Coleta e Processamento de Processos TJRJ

[â¡ï¸ Ir para InstruÃ§Ãµes](#-como-executar)  
[â¡ï¸ Ir para DecisÃµes TÃ©cnicas](#decisÃµes-tÃ©cnicas)

Este projeto implementa um sistema completo de coleta de processos do TJRJ com duas aplicaÃ§Ãµes: uma em Node.js/TypeScript para coleta e outra em C# para processamento.

## ğŸ—ï¸ Arquitetura

O sistema Ã© composto por:

- **Parte 1 (Node.js/TypeScript)**: Coleta processos do TJRJ e envia para RabbitMQ
- **Parte 2 (C#)**: Worker que consome mensagens do RabbitMQ e salva em banco separado
- **PostgreSQL**: Dois bancos separados (um para cada parte)
- **RabbitMQ**: Sistema de mensageria entre as aplicaÃ§Ãµes
- **Docker**: OrquestraÃ§Ã£o completa com docker-compose

## ğŸ“‹ PrÃ©-requisitos

- **Docker** instalado e funcionando
- **Docker Compose** instalado e funcionando
- ConexÃ£o com internet (para coleta de dados do TJRJ)

## ğŸš€ Como Executar

### **1. Executar tudo de uma vez (Recomendado)**

```bash
docker-compose up
```

Este comando vai:

- Subir todos os serviÃ§os (PostgreSQL, RabbitMQ, Parte 1 e Parte 2)
- Executar automaticamente a coleta de dados (Parte 1)
- Iniciar o worker C# para processar as mensagens (Parte 2)

### **2. Executar em background**

```bash
docker-compose up -d
```

### **3. Ver logs em tempo real**

```bash
docker-compose up --follow
```

### **4. Ver logs de serviÃ§os especÃ­ficos**

```bash
# Logs da Parte 1 (Node.js)
docker-compose logs parte1-node

# Logs da Parte 2 (C#)
docker-compose logs parte2-csharp

# Logs do RabbitMQ
docker-compose logs rabbitmq
```

## ğŸ” Verificar Resultados

### **Verificar dados salvos nos bancos:**

```bash
# Verificar dados na Parte 1 (Node.js)
docker-compose exec postgres-parte1 psql -U postgres -d processos_tjrj -c "SELECT COUNT(*) FROM processos;"

# Verificar dados na Parte 2 (C#)
docker-compose exec postgres-parte2 psql -U postgres -d processos_worker -c "SELECT COUNT(*) FROM processos_worker;"
```

### **Ver detalhes dos processos:**

```bash
# Ver processos da Parte 1
docker-compose exec postgres-parte1 psql -U postgres -d processos_tjrj -c "SELECT numero_processo, nome_parte, criado_em FROM processos LIMIT 5;"

# Ver processos da Parte 2
docker-compose exec postgres-parte2 psql -U postgres -d processos_worker -c "SELECT numero_processo, nome_parte, criado_em FROM processos_worker LIMIT 5;"
```

## ğŸŒ Acessos

- **RabbitMQ Management**: http://localhost:15672
  - UsuÃ¡rio: `admin`
  - Senha: `admin`
- **PostgreSQL Parte 1**: localhost:5432
  - Database: `processos_tjrj`
  - UsuÃ¡rio: `postgres`
  - Senha: `postgres`
- **PostgreSQL Parte 2**: localhost:5433
  - Database: `processos_worker`
  - UsuÃ¡rio: `postgres`
  - Senha: `postgres`

## ğŸ“Š O que acontece durante a execuÃ§Ã£o

1. **InicializaÃ§Ã£o dos serviÃ§os**:

   - PostgreSQL parte 1 e parte 2 iniciam
   - RabbitMQ inicia
   - Health checks garantem que os serviÃ§os estejam prontos

2. **Parte 1 (Node.js) executa automaticamente**:

   - Coleta 10 processos do TJRJ
   - Salva no banco `processos_tjrj`
   - Envia mensagens para a fila RabbitMQ `new_processes`
   - Para apÃ³s concluir (graÃ§as ao `docker-compose.override.yml`)

3. **Parte 2 (C#) processa as mensagens**:
   - Consome mensagens da fila RabbitMQ
   - Salva os dados no banco `processos_worker`
   - Fica aguardando novas mensagens

## ğŸ›‘ Comandos de Controle

### **Parar todos os serviÃ§os:**

```bash
docker-compose down
```

### **Parar e remover volumes (dados):**

```bash
docker-compose down -v
```

### **Reconstruir containers:**

```bash
docker-compose down
docker-compose build --no-cache
docker-compose up
```

## ğŸ“ Estrutura do Projeto

```
DesafioElaw/
â”œâ”€â”€ docker-compose.yml          # OrquestraÃ§Ã£o Docker
â”œâ”€â”€ docker-compose.override.yml # ConfiguraÃ§Ãµes especÃ­ficas
â”œâ”€â”€ parte1-node/                # AplicaÃ§Ã£o Node.js/TypeScript
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ index.ts           # Arquivo principal
â”‚   â”‚   â”œâ”€â”€ types/
â”‚   â”‚   â”‚   â””â”€â”€ Process.ts     # Interfaces
â”‚   â”‚   â””â”€â”€ services/
â”‚   â”‚       â”œâ”€â”€ TJRJApiService.ts # Web scraping
â”‚   â”‚       â”œâ”€â”€ DatabaseService.ts # PostgreSQL
â”‚   â”‚       â””â”€â”€ RabbitMQService.ts # RabbitMQ
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ tsconfig.json
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ env.example
â”œâ”€â”€ parte2-csharp/              # AplicaÃ§Ã£o C#
â”‚   â”œâ”€â”€ Worker.cs
â”‚   â”œâ”€â”€ Processo.cs
â”‚   â”œâ”€â”€ Program.cs
â”‚   â”œâ”€â”€ parte2-csharp.csproj
â”‚   â”œâ”€â”€ appsettings.json
â”‚   â””â”€â”€ Dockerfile
â””â”€â”€ README.md
```

## ğŸ”§ ServiÃ§os Docker

- **postgres-parte1**: Banco para a aplicaÃ§Ã£o Node.js (porta 5432)
- **postgres-parte2**: Banco para a aplicaÃ§Ã£o C# (porta 5433)
- **rabbitmq**: Sistema de mensageria (porta 5672, admin 15672)
- **parte1-node**: AplicaÃ§Ã£o de coleta (executa automaticamente)
- **parte2-csharp**: Worker de processamento (aguarda mensagens)

## âš ï¸ ObservaÃ§Ãµes Importantes

### **VariÃ¡veis de Ambiente**

- No Docker, as variÃ¡veis sÃ£o injetadas pelo `docker-compose.yml`
- NÃ£o Ã© necessÃ¡rio arquivo `.env` para execuÃ§Ã£o Docker
- Para desenvolvimento local, copie `env.example` para `.env`

### **Portas Utilizadas**

- **5432**: PostgreSQL Parte 1
- **5433**: PostgreSQL Parte 2
- **5672**: RabbitMQ
- **15672**: RabbitMQ Management

### **PersistÃªncia de Dados**

- Os dados sÃ£o persistidos em volumes Docker
- Para limpar dados: `docker-compose down -v`

### **Logs e Debugging**

- Use `docker-compose logs -f` para ver logs em tempo real
- Cada serviÃ§o tem logs especÃ­ficos para facilitar debugging

## ğŸ¯ Funcionalidades

### Parte 1 - Coleta (Node.js/TypeScript)

- Web scraping do TJRJ com Puppeteer
- Filtros configurados:
  - Origem: 1 InstÃ¢ncia
  - Comarca/Regional: Todas as Comarcas
  - CompetÃªncia: CÃ­vel
  - Nome da Parte: Eduardo
- Coleta dos primeiros 10 processos
- PersistÃªncia em PostgreSQL
- Envio para fila RabbitMQ "new_processes"

### Parte 2 - Processamento (C#)

- Worker que consome mensagens da fila
- PersistÃªncia em banco PostgreSQL separado
- Processamento assÃ­ncrono
- Retry automÃ¡tico em caso de falhas

## ğŸ“ˆ Resultado Esperado

ApÃ³s executar `docker-compose up`, vocÃª deve ver:

- **10 processos** salvos no banco `processos_tjrj` (Parte 1)
- **10 processos** processados e salvos no banco `processos_worker` (Parte 2)
- Logs confirmando o sucesso da operaÃ§Ã£o

## ğŸš¨ Troubleshooting

### **Erro de conexÃ£o com banco**

```bash
docker-compose down
docker-compose up
```

### **Erro de conexÃ£o com RabbitMQ**

- Aguarde alguns segundos para o RabbitMQ inicializar
- Verifique logs: `docker-compose logs rabbitmq`

### **Dados nÃ£o aparecem**

- Verifique se a Parte 1 executou: `docker-compose logs parte1-node`
- Verifique se a Parte 2 processou: `docker-compose logs parte2-csharp`

---

**ğŸ‰ O sistema demonstra comunicaÃ§Ã£o assÃ­ncrona entre aplicaÃ§Ãµes via RabbitMQ com persistÃªncia em bancos separados!**

---

## DecisÃµes TÃ©cnicas

### 1Âª Parte - Feita com Node.js e TypeScript

Optei por desenvolver a primeira parte utilizando Node.js com TypeScript, linguagem com a qual tenho mais familiaridade. Analisei que essa etapa poderia demandar mais esforÃ§o tÃ©cnico, entÃ£o decidi executÃ¡-la com uma stack que domino bem. Inicialmente, tentei realizar o processo via web scraping utilizando a biblioteca Puppeteer, o que funcionou parcialmente, mas percebi que o site do Tribunal de JustiÃ§a implementa algumas medidas para mitigar esse tipo de acesso. Ao inspecionar o network do site, notei que era possÃ­vel realizar requisiÃ§Ãµes diretas Ã  API utilizada pelo front-end.
Essa abordagem simplificou bastante o cÃ³digo, mas me deparei com um problema: em determinados horÃ¡rios, a API exige um token de verificaÃ§Ã£o. Para lidar com isso de forma prÃ¡tica e manter o fluxo funcional, implementei uma verificaÃ§Ã£o que, ao detectar essa exigÃªncia, utiliza um mock com dados reais previamente coletados. O sistema tambÃ©m registra em logs quando essa alternativa foi acionada. ReconheÃ§o que essa Ã© uma soluÃ§Ã£o improvisada, com mais tempo, estudaria uma forma mais robusta de contornar o uso do token, evitando o uso de mocks.

### 2Âª Parte - Feita com C#

A segunda etapa, que consistia em consumir os dados armazenados via fila RabbitMQ, me pareceu mais simples tecnicamente. Tenho conhecimentos bÃ¡sicos de C# e, embora nunca tenha utilizado RabbitMQ antes, jÃ¡ trabalhei com mensageria no Google Cloud Platform usando Pub/Sub. A estrutura que adotei seguiu um padrÃ£o semelhante ao da primeira parte, com arquivos de serviÃ§o separados para lidar com a conexÃ£o ao RabbitMQ e ao banco de dados, em ambas as parte utilizei o banco postgreSQL escolhi por ser um banco que estou acostumado de usar em projetos e por jÃ¡ ter utilizado ele com o docker antes

### 3Âª Parte - OrquestraÃ§Ã£o com Docker

Tenho alguma experiÃªncia com Docker, principalmente em ajustes de arquivos existentes, como DockerFile e docker-compose, e no uso em pipelines de CI/CD com GitHub Actions. Neste desafio, me propus a montar do zero a orquestraÃ§Ã£o dos serviÃ§os. O maior desafio foi garantir a ordem correta de inicializaÃ§Ã£o dos containers, especialmente a conexÃ£o com o RabbitMQ e os bancos de dados. Para isso, implementei uma lÃ³gica de tentativas com retentativas em loop, o que resolveu o problema de forma funcional. Ainda assim, considero esse ponto como uma oportunidade de melhoria, buscando formas mais elegantes e resilientes de garantir a orquestraÃ§Ã£o sem soluÃ§Ãµes improvisadas.
